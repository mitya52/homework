{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Установить Mrec (или альтернативе, по договорённости с преподавателем)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mitya/projects/homework/data/rs\n"
     ]
    }
   ],
   "source": [
    "cd data/rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ipcluster stop &2>/dev/null\n",
    "! ipcluster start -n4 --daemonize\n",
    "! rm -rf tmp && mkdir tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-12-10 16:03:16,840] INFO: sorting input data...\n",
      "[2017-12-10 16:03:16,938] INFO: creating split 0: /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.0 /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.test.0\n",
      "[2017-12-10 16:03:17,254] INFO: creating split 1: /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.1 /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.test.1\n",
      "[2017-12-10 16:03:17,568] INFO: creating split 2: /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.2 /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.test.2\n",
      "[2017-12-10 16:03:17,881] INFO: creating split 3: /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.3 /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.test.3\n",
      "[2017-12-10 16:03:18,194] INFO: creating split 4: /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.4 /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.test.4\n",
      "[2017-12-10 16:03:18,511] INFO: cleaning up...\n",
      "[2017-12-10 16:03:18,513] INFO: done\n",
      "total 4,1M\n",
      "drwxrwxr-x 2 mitya mitya 4,0K дек 10 16:03 .\n",
      "drwxrwxr-x 3 mitya mitya 4,0K дек 10 16:03 ..\n",
      "-rw-rw-r-- 1 mitya mitya 162K дек 10 16:03 u.data.test.0\n",
      "-rw-rw-r-- 1 mitya mitya 163K дек 10 16:03 u.data.test.1\n",
      "-rw-rw-r-- 1 mitya mitya 162K дек 10 16:03 u.data.test.2\n",
      "-rw-rw-r-- 1 mitya mitya 162K дек 10 16:03 u.data.test.3\n",
      "-rw-rw-r-- 1 mitya mitya 162K дек 10 16:03 u.data.test.4\n",
      "-rw-rw-r-- 1 mitya mitya 662K дек 10 16:03 u.data.train.0\n",
      "-rw-rw-r-- 1 mitya mitya 662K дек 10 16:03 u.data.train.1\n",
      "-rw-rw-r-- 1 mitya mitya 662K дек 10 16:03 u.data.train.2\n",
      "-rw-rw-r-- 1 mitya mitya 662K дек 10 16:03 u.data.train.3\n",
      "-rw-rw-r-- 1 mitya mitya 662K дек 10 16:03 u.data.train.4\n"
     ]
    }
   ],
   "source": [
    "! rm -rf tmp/prepared && mkdir tmp/prepared\n",
    "! mrec_prepare --dataset ml-100k/u.data --outdir tmp/prepared --rating_thresh 4 --test_size 0.3 --binarize --min_items_per_user=7\n",
    "! ls -lah tmp/prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-12-10 16:03:19,651] INFO: processing /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.1...\n",
      "[2017-12-10 16:03:19,652] INFO: finding number of items...\n",
      "[2017-12-10 16:03:20,029] INFO: 943 users and 1682 items\n",
      "[2017-12-10 16:03:20,029] INFO: creating sims directory /home/mitya/projects/homework/data/rs/tmp/models/u.data.train.1-sims...\n",
      "[2017-12-10 16:03:20,032] INFO: checking for existing output sims...\n",
      "[2017-12-10 16:03:20,033] INFO: creating tasks...\n",
      "[2017-12-10 16:03:20,033] INFO: running 4 tasks in parallel across ipython engines...\n",
      "[2017-12-10 16:03:22,077] INFO: checking output files...\n",
      "[2017-12-10 16:03:22,078] INFO: SUCCESS: all tasks completed\n",
      "[2017-12-10 16:03:22,078] INFO: concatenating 4 partial output files...\n",
      "[2017-12-10 16:03:22,081] INFO: removing partial output files...\n",
      "[2017-12-10 16:03:22,081] INFO: loading 1682 items in SLIM model from /home/mitya/projects/homework/data/rs/tmp/models/u.data.train.1.sims.tsv\n",
      "[2017-12-10 16:03:22,195] INFO: done\n",
      "[2017-12-10 16:03:22,195] INFO: processing /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.2...\n",
      "[2017-12-10 16:03:22,196] INFO: finding number of items...\n",
      "[2017-12-10 16:03:22,550] INFO: 943 users and 1682 items\n",
      "[2017-12-10 16:03:22,550] INFO: creating sims directory /home/mitya/projects/homework/data/rs/tmp/models/u.data.train.2-sims...\n",
      "[2017-12-10 16:03:22,553] INFO: checking for existing output sims...\n",
      "[2017-12-10 16:03:22,553] INFO: creating tasks...\n",
      "[2017-12-10 16:03:22,553] INFO: running 4 tasks in parallel across ipython engines...\n",
      "[2017-12-10 16:03:24,545] INFO: checking output files...\n",
      "[2017-12-10 16:03:24,545] INFO: SUCCESS: all tasks completed\n",
      "[2017-12-10 16:03:24,545] INFO: concatenating 4 partial output files...\n",
      "[2017-12-10 16:03:24,549] INFO: removing partial output files...\n",
      "[2017-12-10 16:03:24,549] INFO: loading 1682 items in SLIM model from /home/mitya/projects/homework/data/rs/tmp/models/u.data.train.2.sims.tsv\n",
      "[2017-12-10 16:03:24,824] INFO: done\n",
      "[2017-12-10 16:03:24,824] INFO: processing /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.3...\n",
      "[2017-12-10 16:03:24,825] INFO: finding number of items...\n",
      "[2017-12-10 16:03:25,215] INFO: 943 users and 1682 items\n",
      "[2017-12-10 16:03:25,216] INFO: creating sims directory /home/mitya/projects/homework/data/rs/tmp/models/u.data.train.3-sims...\n",
      "[2017-12-10 16:03:25,219] INFO: checking for existing output sims...\n",
      "[2017-12-10 16:03:25,219] INFO: creating tasks...\n",
      "[2017-12-10 16:03:25,219] INFO: running 4 tasks in parallel across ipython engines...\n",
      "[2017-12-10 16:03:27,275] INFO: checking output files...\n",
      "[2017-12-10 16:03:27,275] INFO: SUCCESS: all tasks completed\n",
      "[2017-12-10 16:03:27,276] INFO: concatenating 4 partial output files...\n",
      "[2017-12-10 16:03:27,279] INFO: removing partial output files...\n",
      "[2017-12-10 16:03:27,279] INFO: loading 1682 items in SLIM model from /home/mitya/projects/homework/data/rs/tmp/models/u.data.train.3.sims.tsv\n",
      "[2017-12-10 16:03:27,416] INFO: done\n",
      "[2017-12-10 16:03:27,416] INFO: processing /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.4...\n",
      "[2017-12-10 16:03:27,417] INFO: finding number of items...\n",
      "[2017-12-10 16:03:27,783] INFO: 943 users and 1682 items\n",
      "[2017-12-10 16:03:27,783] INFO: creating sims directory /home/mitya/projects/homework/data/rs/tmp/models/u.data.train.4-sims...\n",
      "[2017-12-10 16:03:27,787] INFO: checking for existing output sims...\n",
      "[2017-12-10 16:03:27,787] INFO: creating tasks...\n",
      "[2017-12-10 16:03:27,787] INFO: running 4 tasks in parallel across ipython engines...\n",
      "[2017-12-10 16:03:29,832] INFO: checking output files...\n",
      "[2017-12-10 16:03:29,832] INFO: SUCCESS: all tasks completed\n",
      "[2017-12-10 16:03:29,832] INFO: concatenating 4 partial output files...\n",
      "[2017-12-10 16:03:29,835] INFO: removing partial output files...\n",
      "[2017-12-10 16:03:29,836] INFO: loading 1682 items in SLIM model from /home/mitya/projects/homework/data/rs/tmp/models/u.data.train.4.sims.tsv\n",
      "[2017-12-10 16:03:29,965] INFO: done\n",
      "[2017-12-10 16:03:29,965] INFO: processing /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.0...\n",
      "[2017-12-10 16:03:29,965] INFO: finding number of items...\n",
      "[2017-12-10 16:03:30,323] INFO: 943 users and 1680 items\n",
      "[2017-12-10 16:03:30,323] INFO: creating sims directory /home/mitya/projects/homework/data/rs/tmp/models/u.data.train.0-sims...\n",
      "[2017-12-10 16:03:30,326] INFO: checking for existing output sims...\n",
      "[2017-12-10 16:03:30,326] INFO: creating tasks...\n",
      "[2017-12-10 16:03:30,326] INFO: running 4 tasks in parallel across ipython engines...\n",
      "[2017-12-10 16:03:32,444] INFO: checking output files...\n",
      "[2017-12-10 16:03:32,444] INFO: SUCCESS: all tasks completed\n",
      "[2017-12-10 16:03:32,444] INFO: concatenating 4 partial output files...\n",
      "[2017-12-10 16:03:32,448] INFO: removing partial output files...\n",
      "[2017-12-10 16:03:32,448] INFO: loading 1680 items in SLIM model from /home/mitya/projects/homework/data/rs/tmp/models/u.data.train.0.sims.tsv\n",
      "[2017-12-10 16:03:32,580] INFO: done\n"
     ]
    }
   ],
   "source": [
    "! rm -rf tmp/models && mkdir tmp/models\n",
    "! mrec_train -n4 --input_format tsv --train \"tmp/prepared/u.data.train.*\" --outdir tmp/models --model=slim --l1_reg=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-12-10 16:03:33,678] INFO: processing /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.1...\n",
      "[2017-12-10 16:03:33,678] INFO: creating recs directory /home/mitya/projects/homework/data/rs/tmp/recs/u.data.train.1-recs...\n",
      "[2017-12-10 16:03:33,681] INFO: checking for existing output recs...\n",
      "[2017-12-10 16:03:33,681] INFO: creating tasks...\n",
      "[2017-12-10 16:03:33,682] INFO: loading dataset to get size...\n",
      "[2017-12-10 16:03:34,040] INFO: loading model to get size...\n",
      "[2017-12-10 16:03:34,079] INFO: created 1 tasks, 287016 users per task\n",
      "[2017-12-10 16:03:34,079] INFO: running in parallel across ipython engines...\n",
      "[2017-12-10 16:03:35,046] INFO: checking output files...\n",
      "[2017-12-10 16:03:35,046] INFO: SUCCESS: all tasks completed\n",
      "[2017-12-10 16:03:35,046] INFO: concatenating 1 partial output files...\n",
      "[2017-12-10 16:03:35,051] INFO: removing partial output files...\n",
      "[2017-12-10 16:03:35,051] INFO: done\n",
      "[2017-12-10 16:03:35,052] INFO: processing /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.2...\n",
      "[2017-12-10 16:03:35,052] INFO: creating recs directory /home/mitya/projects/homework/data/rs/tmp/recs/u.data.train.2-recs...\n",
      "[2017-12-10 16:03:35,056] INFO: checking for existing output recs...\n",
      "[2017-12-10 16:03:35,056] INFO: creating tasks...\n",
      "[2017-12-10 16:03:35,056] INFO: loading dataset to get size...\n",
      "[2017-12-10 16:03:35,457] INFO: loading model to get size...\n",
      "[2017-12-10 16:03:35,459] INFO: created 1 tasks, 284600 users per task\n",
      "[2017-12-10 16:03:35,460] INFO: running in parallel across ipython engines...\n",
      "[2017-12-10 16:03:36,488] INFO: checking output files...\n",
      "[2017-12-10 16:03:36,488] INFO: SUCCESS: all tasks completed\n",
      "[2017-12-10 16:03:36,488] INFO: concatenating 1 partial output files...\n",
      "[2017-12-10 16:03:36,492] INFO: removing partial output files...\n",
      "[2017-12-10 16:03:36,492] INFO: done\n",
      "[2017-12-10 16:03:36,493] INFO: processing /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.3...\n",
      "[2017-12-10 16:03:36,493] INFO: creating recs directory /home/mitya/projects/homework/data/rs/tmp/recs/u.data.train.3-recs...\n",
      "[2017-12-10 16:03:36,497] INFO: checking for existing output recs...\n",
      "[2017-12-10 16:03:36,498] INFO: creating tasks...\n",
      "[2017-12-10 16:03:36,498] INFO: loading dataset to get size...\n",
      "[2017-12-10 16:03:36,869] INFO: loading model to get size...\n",
      "[2017-12-10 16:03:36,871] INFO: created 1 tasks, 289523 users per task\n",
      "[2017-12-10 16:03:36,871] INFO: running in parallel across ipython engines...\n",
      "[2017-12-10 16:03:37,866] INFO: checking output files...\n",
      "[2017-12-10 16:03:37,866] INFO: SUCCESS: all tasks completed\n",
      "[2017-12-10 16:03:37,867] INFO: concatenating 1 partial output files...\n",
      "[2017-12-10 16:03:37,874] INFO: removing partial output files...\n",
      "[2017-12-10 16:03:37,874] INFO: done\n",
      "[2017-12-10 16:03:37,876] INFO: processing /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.4...\n",
      "[2017-12-10 16:03:37,876] INFO: creating recs directory /home/mitya/projects/homework/data/rs/tmp/recs/u.data.train.4-recs...\n",
      "[2017-12-10 16:03:37,881] INFO: checking for existing output recs...\n",
      "[2017-12-10 16:03:37,881] INFO: creating tasks...\n",
      "[2017-12-10 16:03:37,882] INFO: loading dataset to get size...\n",
      "[2017-12-10 16:03:38,242] INFO: loading model to get size...\n",
      "[2017-12-10 16:03:38,244] INFO: created 1 tasks, 287139 users per task\n",
      "[2017-12-10 16:03:38,244] INFO: running in parallel across ipython engines...\n",
      "[2017-12-10 16:03:39,210] INFO: checking output files...\n",
      "[2017-12-10 16:03:39,210] INFO: SUCCESS: all tasks completed\n",
      "[2017-12-10 16:03:39,210] INFO: concatenating 1 partial output files...\n",
      "[2017-12-10 16:03:39,215] INFO: removing partial output files...\n",
      "[2017-12-10 16:03:39,215] INFO: done\n",
      "[2017-12-10 16:03:39,216] INFO: processing /home/mitya/projects/homework/data/rs/tmp/prepared/u.data.train.0...\n",
      "[2017-12-10 16:03:39,216] INFO: creating recs directory /home/mitya/projects/homework/data/rs/tmp/recs/u.data.train.0-recs...\n",
      "[2017-12-10 16:03:39,221] INFO: checking for existing output recs...\n",
      "[2017-12-10 16:03:39,221] INFO: creating tasks...\n",
      "[2017-12-10 16:03:39,221] INFO: loading dataset to get size...\n",
      "[2017-12-10 16:03:39,609] INFO: loading model to get size...\n",
      "[2017-12-10 16:03:39,611] INFO: created 1 tasks, 284117 users per task\n",
      "[2017-12-10 16:03:39,611] INFO: running in parallel across ipython engines...\n",
      "[2017-12-10 16:03:40,600] INFO: checking output files...\n",
      "[2017-12-10 16:03:40,600] INFO: SUCCESS: all tasks completed\n",
      "[2017-12-10 16:03:40,600] INFO: concatenating 1 partial output files...\n",
      "[2017-12-10 16:03:40,604] INFO: removing partial output files...\n",
      "[2017-12-10 16:03:40,604] INFO: done\n",
      "SLIM(SGDRegressor(alpha=0.0101, average=False, epsilon=0.1, eta0=0.01,\n",
      "       fit_intercept=False, l1_ratio=0.9900990099009902,\n",
      "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
      "       n_iter=None, penalty='elasticnet', power_t=0.25, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False))\n",
      "mrr            0.6554 +/- 0.0032\n",
      "prec@5         0.3829 +/- 0.0023\n",
      "prec@10        0.3145 +/- 0.0007\n",
      "prec@15        0.2741 +/- 0.0005\n",
      "prec@20        0.2451 +/- 0.0006\n"
     ]
    }
   ],
   "source": [
    "! rm -rf tmp/recs && mkdir tmp/recs\n",
    "! mrec_predict --input_format tsv --test_input_format tsv --train \"tmp/prepared/u.data.train.*\" --modeldir tmp/models/ --outdir tmp/recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t50\t1.0100884654177793\r\n",
      "1\t423\t0.46517269995272925\r\n",
      "1\t96\t0.45665582031827967\r\n",
      "1\t168\t0.4552554712989447\r\n",
      "1\t173\t0.43120327922252144\r\n",
      "1\t475\t0.42956109322882313\r\n",
      "1\t79\t0.37197817889206664\r\n",
      "1\t22\t0.3552901814508858\r\n",
      "1\t23\t0.34935208851547844\r\n",
      "1\t655\t0.34823913674277274\r\n"
     ]
    }
   ],
   "source": [
    "! head tmp/recs/u.data.train.0.recs.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fixed result to repo\n",
    "# prepared, models, recs\n",
    "! rm -rf ../../results/mrec-4-2 && mkdir -p ../../results/mrec-4-2\n",
    "! cp -R tmp/* ../../results/mrec-4-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mitya/projects/homework\n"
     ]
    }
   ],
   "source": [
    "cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Получить для MovieLens 100K рекомендации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ipcluster stop &2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from os import path\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename: str):\n",
    "    data_dir = 'data/rs/ml-latest-small'\n",
    "    data = pd.read_csv(path.join(data_dir, filename + \".csv\"))\n",
    "    return data\n",
    "\n",
    "def sparse_info(sparse_matrix: csr_matrix):\n",
    "    print(\"Размерности матрицы: {}\".format(sparse_matrix.shape))\n",
    "    print(\"Ненулевых элементов в матрице: {}\".format(sparse_matrix.nnz))\n",
    "    print(\"Доля ненулевых элементов: {}\"\n",
    "          .format(sparse_matrix.nnz / sparse_matrix.shape[0] / sparse_matrix.shape[1])\n",
    "    )\n",
    "    print(\"Среднее значение ненулевых элементов: {}\".format(sparse_matrix.data.mean()))\n",
    "    print(\"Максимальное значение ненулевых элементов: {}\".format(sparse_matrix.data.max()))\n",
    "    print(\"Минимальное значение ненулевых элементов: {}\".format(sparse_matrix.data.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = read_csv(\"ratings\")\n",
    "movies = read_csv(\"movies\")\n",
    "ratings[\"movie_id\"] = ratings[\"movieId\"].astype(\"category\").cat.codes.copy() + 1\n",
    "\n",
    "last_movie_id = ratings[\"movie_id\"].max()\n",
    "last_user_id = ratings[\"userId\"].max()\n",
    "mean_rating = ratings[\"rating\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерности матрицы: (672, 9067)\n",
      "Ненулевых элементов в матрице: 100004\n",
      "Доля ненулевых элементов: 0.01641286822438251\n",
      "Среднее значение ненулевых элементов: -8.544580154534742e-09\n",
      "Максимальное значение ненулевых элементов: 1.45639169216156\n",
      "Минимальное значение ненулевых элементов: -3.0436081886291504\n"
     ]
    }
   ],
   "source": [
    "user_x_item = ratings[[\"userId\", \"movie_id\"]].as_matrix()\n",
    "user_item_matrix = csr_matrix(\n",
    "    (\n",
    "        (ratings[\"rating\"] - mean_rating).tolist(),\n",
    "        (\n",
    "            [pair[0] for pair in user_x_item],\n",
    "            [pair[1] for pair in user_x_item],\n",
    "        )\n",
    "    ),\n",
    "    shape=(last_user_id + 1, last_movie_id + 1),\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "sparse_info(user_item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### по популярности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9067, 9067)\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "similarity_matrix = squareform(\n",
    "    1 - pdist(\n",
    "        user_item_matrix.todense().T,\n",
    "        metric=\"cosine\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(similarity_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['movieId', 'title', 'genres'], dtype='object'),\n",
       " Index(['userId', 'movieId', 'rating', 'timestamp', 'movie_id'], dtype='object'))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.columns, ratings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n"
     ]
    }
   ],
   "source": [
    "for ind, row in movies.iterrows():\n",
    "    jnd = row.title.find('Pulp Fiction')\n",
    "    if jnd >= 0:\n",
    "        r = ratings[ratings.movieId==row.movieId].iloc[0]\n",
    "        print(int(r.movie_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>47</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>50</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>318</td>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>593</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "      <td>Crime|Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>608</td>\n",
       "      <td>Fargo (1996)</td>\n",
       "      <td>Comedy|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>858</td>\n",
       "      <td>Godfather, The (1972)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1089</td>\n",
       "      <td>Reservoir Dogs (1992)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>1213</td>\n",
       "      <td>Goodfellas (1990)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>2858</td>\n",
       "      <td>American Beauty (1999)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>2959</td>\n",
       "      <td>Fight Club (1999)</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                             title                       genres\n",
       "45         47       Seven (a.k.a. Se7en) (1995)             Mystery|Thriller\n",
       "48         50        Usual Suspects, The (1995)       Crime|Mystery|Thriller\n",
       "284       318  Shawshank Redemption, The (1994)                  Crime|Drama\n",
       "525       593  Silence of the Lambs, The (1991)        Crime|Horror|Thriller\n",
       "535       608                      Fargo (1996)  Comedy|Crime|Drama|Thriller\n",
       "695       858             Godfather, The (1972)                  Crime|Drama\n",
       "880      1089             Reservoir Dogs (1992)       Crime|Mystery|Thriller\n",
       "969      1213                 Goodfellas (1990)                  Crime|Drama\n",
       "2288     2858            American Beauty (1999)                Drama|Romance\n",
       "2374     2959                 Fight Club (1999)  Action|Crime|Drama|Thriller"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def get_similar_movies(movie_id: int, n: int) -> list:\n",
    "    return (-similarity_matrix[movie_id, :]).argsort()[:n]\n",
    "\n",
    "similar_movies = get_similar_movies(267, 10)\n",
    "movies[movies[\"movieId\"].isin(\n",
    "    ratings[ratings[\"movie_id\"].isin(similar_movies)][\"movieId\"].tolist()\n",
    ")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### с помощью kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерности матрицы: (9067, 9067)\n",
      "Ненулевых элементов в матрице: 21983224\n",
      "Доля ненулевых элементов: 0.26740169371818234\n",
      "Среднее значение ненулевых элементов: 0.04221750795841217\n",
      "Максимальное значение ненулевых элементов: 1.0000016689300537\n",
      "Минимальное значение ненулевых элементов: -1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize, binarize\n",
    "\n",
    "def get_cosine_similarity_matrix(user_item_matrix):\n",
    "    user_item_csr = user_item_matrix.tocsr()\n",
    "    user_item_normalized = normalize(user_item_csr, norm='l2', axis=0)\n",
    "    return user_item_normalized.T.dot(user_item_normalized)\n",
    "\n",
    "similarity_matrix = get_cosine_similarity_matrix(user_item_matrix)\n",
    "sparse_info(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерности матрицы: (9067, 9067)\n",
      "Ненулевых элементов в матрице: 63462\n",
      "Доля ненулевых элементов: 0.000771945292771583\n",
      "Среднее значение ненулевых элементов: 0.7470669150352478\n",
      "Максимальное значение ненулевых элементов: 1.0\n",
      "Минимальное значение ненулевых элементов: -0.04087800905108452\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import vstack, csr_matrix\n",
    "\n",
    "def get_top_k_in_a_row(similarity_matrix, row, k, no_diagonal):\n",
    "    lil_row = similarity_matrix[row]\n",
    "    if no_diagonal:\n",
    "        lil_row[0, row] = 0\n",
    "    csr_row = lil_row.tocsr()\n",
    "    csr_row.data[csr_row.data.argsort()[:-k]] = 0\n",
    "    csr_row.eliminate_zeros()\n",
    "    return csr_row\n",
    "\n",
    "def get_top_k(similarity_matrix, k, no_diagonal=True):\n",
    "    lil_similarity = similarity_matrix.tolil()\n",
    "    top_k_similarity_matrix = get_top_k_in_a_row(lil_similarity, 0, k, no_diagonal)\n",
    "    for row in range(1, lil_similarity.shape[0]):\n",
    "        if len(lil_similarity.rows[row]) > 0:\n",
    "            csr_row = get_top_k_in_a_row(lil_similarity, row, k, no_diagonal)\n",
    "            top_k_similarity_matrix = vstack([top_k_similarity_matrix, csr_row])\n",
    "    return top_k_similarity_matrix\n",
    "\n",
    "top_k_similarity_matrix = get_top_k(similarity_matrix, 7)\n",
    "sparse_info(top_k_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 10000\n",
      "Размер тестовой выборки: 90004\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "np.random.seed(123123)\n",
    "train_percent = 0.1\n",
    "user_item_matrix = user_item_matrix.tocoo()\n",
    "train_split = np.random.choice(\n",
    "    range(user_item_matrix.nnz),\n",
    "    int(user_item_matrix.nnz * train_percent),\n",
    "    replace=False\n",
    ")\n",
    "test_split = list(set(range(user_item_matrix.nnz)) - set(train_split))\n",
    "train_matrix = coo_matrix(\n",
    "    (\n",
    "        user_item_matrix.data[train_split],\n",
    "        (user_item_matrix.row[train_split], user_item_matrix.col[train_split])\n",
    "    ),\n",
    "    shape=user_item_matrix.shape\n",
    ")\n",
    "test_matrix = coo_matrix(\n",
    "    (\n",
    "        user_item_matrix.data[test_split],\n",
    "        (user_item_matrix.row[test_split], user_item_matrix.col[test_split])\n",
    "    ),\n",
    "    shape=user_item_matrix.shape\n",
    ")\n",
    "print(\"Размер обучающей выборки:\", train_matrix.nnz)\n",
    "print(\"Размер тестовой выборки:\", test_matrix.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "точность нашего baseline\n",
      "1.05751754112\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "def RMSE(matrix1: coo_matrix, matrix2: coo_matrix):\n",
    "    arr = (matrix1 - matrix2).data\n",
    "    return np.sqrt(reduce(lambda x, y: x + y**2, arr) / len(arr))\n",
    "\n",
    "mean_rating_prediction = 0 * test_matrix\n",
    "print(\"точность нашего baseline\")\n",
    "print(RMSE(mean_rating_prediction, test_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "получили предсказаний всего\n",
      "62305\n",
      "оставили предсказаний для теста\n",
      "6614\n"
     ]
    }
   ],
   "source": [
    "normalized_similarity = normalize(top_k_similarity_matrix.tocsr(), norm=\"l1\", axis=0)\n",
    "raw_predictions = train_matrix.dot(normalized_similarity).tocoo()\n",
    "print(\"получили предсказаний всего\")\n",
    "print(len(raw_predictions.data))\n",
    "\n",
    "filtered_predictions = binarize(test_matrix).multiply(raw_predictions)\n",
    "print(\"оставили предсказаний для теста\")\n",
    "print(len(filtered_predictions.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.04882443211\n"
     ]
    }
   ],
   "source": [
    "print(RMSE(filtered_predictions, test_matrix))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
