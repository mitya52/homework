{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные из файлов\n",
    "train = pd.read_csv('data/titanic/train.csv')\n",
    "test = pd.read_csv('data/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем столбец идентификаторов пассажиров для тестовых данных\n",
    "test_passenger_id = test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных, добавление признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python\n",
    "\n",
    "import re\n",
    "\n",
    "RARE_TITLES = ['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "\n",
    "# создаем словарь для исправления префиксов имени\n",
    "TITLES = dict((title, 'Rare') for title in RARE_TITLES)\n",
    "\n",
    "TITLES['Mlle'] = 'Miss'\n",
    "TITLES['Ms'] = 'Miss'\n",
    "TITLES['Mme'] = 'Mrs'\n",
    "\n",
    "def get_title(name):\n",
    "    \"\"\" Возвращает префикс имени \"\"\"\n",
    "    match = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if match:\n",
    "        # исправляем опечатки в префиксе имени\n",
    "        return TITLES.get(match.group(1), match.group(1))\n",
    "    return ''\n",
    "\n",
    "# Применяем процесс для обучающего и тестового наборов\n",
    "for dataset in [test, train]:\n",
    "    # длина имени\n",
    "    dataset['Name_Length'] = train['Name'].apply(len)\n",
    "    # была ли каюта у пассажира\n",
    "    dataset['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "    # сколько членов семьи было на корабле\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    # флаг = 1, если путешествует в одиночестве\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    # заполняем пропуски для Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "    # заполняем индексами\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    # заполняем пропуски Fare медианой\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "    # заполняем пропуски возраста медианой\n",
    "    dataset['Age'] = dataset['Age'].fillna(train['Age'].median())\n",
    "    # добавляем префикс имени как отдельный категориальный признак\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "    dataset['Title'] = dataset['Title'].map( {'Mr': 1, \n",
    "                                              'Miss': 2, \n",
    "                                              'Mrs': 3,\n",
    "                                              'Master': 4,\n",
    "                                              'Rare': 5} )\n",
    "    # заполняем неизвестные префиксы нулями\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    # бинаризуем пол\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    # категоризируем стоимость билета\n",
    "    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n",
    "    dataset.loc[dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    # категоризируем возраст\n",
    "    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[dataset['Age'] > 64, 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем неиспользуемые столбцы\n",
    "DROP_COL = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "\n",
    "X_train = np.array(train.drop(DROP_COL + ['Survived'], axis=1))\n",
    "y_train = np.array(train['Survived'])\n",
    "X_test = np.array(test.drop(DROP_COL, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание моделей для стеккинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "random_state=123123\n",
    "estimators = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_params(estimator, params, meta=False):\n",
    "    correct = dict()\n",
    "    pref = \"{}__\".format(estimator.__class__.__name__.lower())\n",
    "    if meta:\n",
    "        pref = \"meta-{}\".format(pref)\n",
    "    for k, v in params.items():\n",
    "        correct[pref+k] = v\n",
    "    return correct\n",
    "\n",
    "def get_best(est, params, X2train=X_train):\n",
    "    grid = GridSearchCV(estimator=est, param_grid=params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X2train, y_train)\n",
    "    print('Best score for {}: {}'.format(est.__class__.__name__, grid.best_score_))\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for RandomForestClassifier: 0.8294051627384961\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfcp = {\n",
    "    'n_estimators': [15, 20, 25, 30],\n",
    "    'criterion': ['entropy'],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [2, 3, 5, 8],\n",
    "    'min_samples_leaf': [2, 3, 5, 7],\n",
    "    'random_state': [random_state],\n",
    "}\n",
    "\n",
    "estimators.append(get_best(rfc, rfcp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for ExtraTreesClassifier: 0.8237934904601572\n"
     ]
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier()\n",
    "etcp = rfcp.copy()\n",
    "\n",
    "estimators.append(get_best(etc, etcp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for AdaBoostClassifier: 0.8237934904601572\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "abcp = {\n",
    "    'n_estimators': [1000, 1050, 1100, 1150, 1200],\n",
    "    'learning_rate': [0.01],\n",
    "    'random_state': [random_state],\n",
    "}\n",
    "\n",
    "estimators.append(get_best(abc, abcp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for XGBClassifier: 0.8316498316498316\n"
     ]
    }
   ],
   "source": [
    "xgbc = XGBClassifier()\n",
    "xgbcp = {\n",
    "    'n_estimators' : range(550, 650, 25),\n",
    "    'learning_rate' : [0.01],\n",
    "    'max_depth' : [2, 3, 5],\n",
    "    'gamma' : [0.45, 0.5],\n",
    "    'objective': [\"reg:linear\", \"reg:logistic\"],\n",
    "    'silent' : [1],\n",
    "    'colsample_bytree': [1.0],\n",
    "    'reg_alpha': [0.18, 0.2, 0.22],\n",
    "    'reg_lambda': [1.0],\n",
    "    'random_state': [random_state],\n",
    "}\n",
    "\n",
    "estimators.append(get_best(xgbc, xgbcp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "             max_depth=8, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=2, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "             oob_score=False, random_state=123123, verbose=0,\n",
       "             warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
       "            max_depth=5, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=1,\n",
       "            oob_score=False, random_state=123123, verbose=0,\n",
       "            warm_start=False),\n",
       " AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "           learning_rate=0.01, n_estimators=1000, random_state=123123),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=1.0, gamma=0.45, learning_rate=0.01,\n",
       "        max_delta_step=0, max_depth=2, min_child_weight=1, missing=None,\n",
       "        n_estimators=550, n_jobs=1, nthread=None, objective='reg:linear',\n",
       "        random_state=123123, reg_alpha=0.2, reg_lambda=1.0,\n",
       "        scale_pos_weight=1, seed=None, silent=1, subsample=1)]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stack = np.array([est.predict_proba(X_train)[:,1] for est in estimators]).T\n",
    "X_test_stack = np.array([est.predict_proba(X_test)[:,1] for est in estimators]).T\n",
    "estimators_stack = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## second stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for LogisticRegression: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lrp = {\n",
    "    'C': [0.01, 0.03, 0.08, 0.1, 0.3, 0.6, 1.0, 3., 5., 9., 10.0, 11., 12.],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'random_state': [random_state],\n",
    "}\n",
    "\n",
    "estimators_stack.append(get_best(lr, lrp, X_train_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for XGBClassifier: 0.9057239057239057\n"
     ]
    }
   ],
   "source": [
    "xgbc = XGBClassifier()\n",
    "xgbcp = {\n",
    "    'n_estimators' : range(800, 900, 25),\n",
    "    'learning_rate' : [0.01],\n",
    "    \n",
    "    'max_depth' : [2, 3, 5],\n",
    "    #'gamma' : [0.45, 0.5, 0.55],\n",
    "    'objective': [\"reg:linear\", \"reg:logistic\"],\n",
    "    'silent' : [1],\n",
    "    'colsample_bytree': [1.0],\n",
    "    'reg_alpha': [0.7, 0.9, 1.1, 1.3, 3., 5.],\n",
    "    'reg_lambda': [1.0],\n",
    "    'random_state': [random_state],\n",
    "}\n",
    "\n",
    "estimators_stack.append(get_best(xgbc, xgbcp, X_train_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=9.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l1', random_state=123123, solver='liblinear',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "        colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
       "        max_depth=3, min_child_weight=1, missing=None, n_estimators=875,\n",
       "        n_jobs=1, nthread=None, objective='reg:linear', random_state=123123,\n",
       "        reg_alpha=0.7, reg_lambda=1.0, scale_pos_weight=1, seed=None,\n",
       "        silent=1, subsample=1)]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stack_second = np.array([est.predict_proba(X_train_stack)[:,1] for est in estimators_stack]).T\n",
    "X_test_stack_second = np.array([est.predict_proba(X_test_stack)[:,1] for est in estimators_stack]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for LogisticRegression: 0.936026936026936\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lrp = {\n",
    "    'C': [0.01, 0.03, 0.08, 0.1, 0.3, 0.6, 1.0, 3., 5., 9., 10.0, 11., 12.],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'random_state': [random_state],\n",
    "}\n",
    "\n",
    "classifier = get_best(lr, lrp, X_train_stack_second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = classifier.predict(X_test_stack_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.txt', 'w') as out:\n",
    "    out.write('PassengerId,Survived\\n')\n",
    "    for passenger, y in zip(test_passenger_id, predicted):\n",
    "        out.write('%s,%s\\n' % (passenger, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
